#!/usr/bin/env python

# set username and password in .netrc

import requests
import json
import sys
import os
import shutil
import urllib3
#urllib3.disable_warnings()
from wfutils import config


_reasons =  [
        {'str': 'jgi.RQCFilterStats.toString', "msg": "Failed rqc bug"},
        {'str': 'No bins generated by metabat', "msg": "MAG binning bug"},
        {'str': 'hqmq_bin.zip', "msg": "MAG binning bug2"},
        {'str': "KeyError: 'scaffold", "msg": "Multiple shortened bug"},
        {'str': "too many arguments", "msg": "Bad zip command"},
        {'str': "Mismatch between length of bases and qualities for read", "msg": "Bad reads"}
        ]


class CQ():
    conf = config().conf
    base = conf['url']
    
    def abort_job(self, job_id):
        url = "%s/%s/abort" %(self.base, job_id)
        resp = requests.post(url, verify=False).json()
        return resp

    def meta(self, job_id, expand=True):
        expand_s = "false"
        if expand:
            expand_s = "true"

        url = "%s/%s/metadata?expandSubWorkflows=%s" %(self.base, job_id, expand_s)
        resp = requests.post(url, timeout=60).json()
        return resp

    def labels(self, job_id):
        url = "%s/%s/labels" %(self.base, job_id)
        resp = requests.get(url).json()
        return resp

    def trav(self, w):
        if 'calls' in w:
            for name in w['calls']:
                for task in w['calls'][name]:
                    if task['executionStatus'] == 'Failed':
                        if 'subWorkflowMetadata' in task:
                            t = self.trav(task['subWorkflowMetadata'])
                            if t:
                                return t
                        else:
                            return task
        else:
            return w

    def diagnose(self, job_id):
        """
        Try to diagnose why a job failed.
        """
        meta = self.meta(job_id)
        failed_task = self.trav(meta)
        if not failed_task or 'stderr' not in failed_task:
            return "Failed to find failed task"
        elif os.path.exists(failed_task['stderr']):
            stderr = open(failed_task['stderr']).read()
        else:
            stderr = None

        msg = None
        if not stderr:
            if 'Unable to start job' in failed_task['failures'][0]['message']:
                msg = "Failed submission"
            else:
                msg = "Missing stderr"
        else:
            for r in _reasons:
                if r['str'] in stderr:
                    msg = r['msg']
        if not msg:
            msg = "unknown"
        return msg

    def dump_stderr(self, job_id):
        """
        Dump stderr for a failed task
        """
        meta = self.meta(job_id)
        failed_task = self.trav(meta)
        if os.path.exists(failed_task['stderr']):
            print("Dumping %s" % (failed_task['stderr']))
            stderr = open(failed_task['stderr']).read()
            print(stderr)

    def copy_output(self, job_id, outdir):
        url = "%s/%s/metadata" %(self.base, job_id)
        if not os.path.exists(outdir):
            os.makedirs(outdir)
        resp = requests.get(url, verify=False)
        outs = resp.json()['outputs']
        for k in outs:
            print("Copying " + k)
            fn = outs[k]
            shutil.copy(fn, os.path.join(outdir, os.path.basename(fn)))

    def job_status(self, job_id):
        url = "%s/%s/status" %(self.base, job_id)
        resp = requests.get(url, verify=False).json()
        return resp

    def list_jobs(self, status, type=None, key=None, value=None, labels=False):
            if status == 'All':
                query = "includeSubworkflows=false&additionalQueryResultFields=labels"
            elif key and value:
                query = "label={}:{}&additionalQueryResultFields=labels".format(key, value)
            elif labels:
            #query = "status=Succeeded&additionalQueryResultFields=labels&includeSubworkflows=false"
                query = "status={}&additionalQueryResultFields=labels&includeSubworkflows=false".format(status)
            else:
                query = "status={}".format(status)
            url = "%s/query?%s" % (self.base, query)
            resp = requests.get(url, verify=False)
            d = resp.json()
            resp = []
            for i in d['results']:
                for k in ['parentWorkflowId', 'rootWorkflowId', 'name', 'start']:
                    if k not in i:
                        i[k] = '-'

                if labels:
                    if 'labels' not in i:
                        continue
                    i['proj'] = i['labels'].get('project_id', '-')
                    i['vers'] = i['labels'].get('pipeline_version', '-')
                    i['pipeline'] = i['labels'].get('pipeline', '-')
                    i['activity_id'] = i['labels'].get('activity_id', '-')
                    i['opid'] = i['labels'].get('opid', '-')
                resp.append(i)
            return resp
#                    print("{id:36}  {name:14} {status:10} {proj:15} {vers:9}  {pipeline:16} {activity_id:14} {start}".format(**i))
#                else:
#                    print("{id:36}  {name:14} {parentWorkflowId:36}  {rootWorkflowId:36}  {status}   {start}".format(**i))


    def jobs(self, jid, filt):
        url = '{}/{}/metadata'.format(self.base, jid)
        data = {}
        resp = requests.get(url)
    
        d = resp.json()
        for f in d['calls']:
            for s in d['calls'][f]:
                if filt and f.find(filt)<0:
                    continue
                if 'jobId' in s:
                    print("#{} {}".format(f, jid), file=sys.stderr)
                    print(s['jobId'])

    def get_jid(self, jid, status, filt):
    
        url = "{}/query?status={}&additionalQueryResultFields=labels".format(self.base, status)
        data = {}
        resp = requests.get(url, verify=False)
        d = resp.json()
        for i in d['results']:
            if 'parentWorkflowId' not in i:
                i['parentWorkflowId'] = '-'
            if 'rootWorkflowId' not in i:
                i['rootWorkflowId'] = '-'
            if 'name' not in i:
                i['name']=""
            if jid and i['id'] == jid:
                self.jobs(i['id'], filt)
            elif jid and i['rootWorkflowId'] == jid:
                self.jobs(i['id'], filt)
            elif not jid:
                self.jobs(i['id'], filt)


def check_arg(ct):
    if len(sys.argv) < ct:
        print("arg required")
        sys.exit(1)

def usage():
    print("usage: cq <abort|status|running|submitted|all|labels|meta>")

def main():
    cq = CQ()
    states = ['running', 'failed', 'submitted',
              'aborted', 'aborting', 'all', 'succeeded']

    if len(sys.argv) < 2:
        usage()
        sys.exit(1)

    command = sys.argv[1]
    if len(sys.argv) > 2:
        job_id = sys.argv[2]
    if command=='abort':
        check_arg(3)
        print(cq.abort_job(job_id))
    
    elif command=='copy':
        check_arg(4)
        outdir = sys.argv[3]
        cq.copy_output(job_id, outdir)
    elif  command=='status':
        check_arg(3)
        resp = cq.job_status(job_id)
        print(resp) 
    elif  command.startswith('meta'):
        resp = cq.meta(job_id)
        print(json.dumps(resp, indent=4)) 
    elif  command.startswith('metas'):
        resp = cq.meta(job_id, expand=False)
        print(json.dumps(resp, indent=4)) 
    elif  command=='graph':
        url = "%s/%s/timing" %(job_id)
        resp = requests.get(url, verify=False)
        with open(sys.argv[3], "w") as f:
            f.write(resp.text)
    elif command=='labels':
        status = 'All'
        if len(sys.argv) > 2:
            status = sys.argv[2]
        resp = cq.list_jobs(status, labels=True)
        for i in resp:
            print("{id:36}  {name:14} {status:10} {proj:15} {vers:9}  {pipeline:16} {activity_id:14} {opid:12} {start}".format(**i))
    elif command in states:
        status = command.capitalize()
        resp = cq.list_jobs(status)
        for i in resp:
            print("{id:36}  {name:14} {parentWorkflowId:36}  {rootWorkflowId:36}  {status}   {start}".format(**i))
    elif  command=='search_label':
        key = sys.argv[2]
        value = sys.argv[3]
        resp = cq.list_jobs('label', key=key, value=value)
        for i in resp:
            print("{id:36}  {name:14} {status:10} {proj:15} {vers:9}  {pipeline:16} {activity_id:14} {start}".format(**i))
    elif  command.startswith('diag'):
        j = sys.argv[2]
        labels = cq.labels(j)
        msg = cq.diagnose(j)
        print("%s: %s: %s" %(j, labels.get('activity_id'), msg))
    elif  command.startswith('stderr'):
        j = sys.argv[2]
        cq.dump_stderr(j)
    elif command=='jid':
        filt = None
        jid = None
        status = 'Running'
        if len(sys.argv) > 2 and sys.argv[2]!='-':
            jid = sys.argv[2]
        if len(sys.argv) > 3 and sys.argv[3]!='-':
            filt = sys.argv[3]
        if len(sys.argv) > 4:
            status = sys.argv[4].capitalize()
        cq.get_jid(jid, status, filt)
    else:
        print("{} not recongnized".format(command))
        usage()
        sys.exit(1)


def jprint(obj):
    print(json.dumps(obj, indent=2))


if __name__ == '__main__':
    main()
